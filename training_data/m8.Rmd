
This notebook is for training m8,  
# m8 age, gender, country,  education level,  education_title , profession, years_experience  ,  working  , salary ,  balance   > spendingBehaviour


#Models compared:

##1 Random Forest
##2 Logistic Regression
#3 decision tree
 
 
#Model chosed:
# Random Forest
 
The overall accuracy were compared between all models. 

 
 
Note. In case you want to chose a different model i.e. if you update the data or you have a different opinion.
Just assign the m1 model to your newly chosed model at the end of this notebook.

```{r}
#saveRDS(m1_rf_model, "m1.rds")

```


```{r}
rm(list = ls())

library(openxlsx)
library(caret)
library(nnet)         # for multinom
library(randomForest) # for random forest
library(rpart)        # for decision tree
library(class)        # for KNN
library(randomForest)
library(caret)
library(xgboost)
library(pROC)
library(MLmetrics)
library(dplyr)

# Read the Excel file
df <- read.xlsx("ai_traininig_df_final.xlsx", sheet = 1) 
df
```

#Data preparation:

```{r}
library(caret)

df =   df[complete.cases(df), ]  
 
df$gender <- factor(df$gender)
df$country <- factor(df$country)
df$education_level <- factor(df$education_level)
df$education_title <- factor(df$education_title)
df$profession <- factor(df$profession)
df$years_experience = as.integer(df$years_experience)
df$salary_eur = as.integer(df$salary_eur)
df$balance_eur = as.integer(df$balance_eur)
df$working = factor( df$working)
df$spendingBehaviour =  factor( df$spendingBehaviour)
#Splitting the data into training and testing sets
set.seed(42)   
trainIndex <- createDataPartition(df$profession, p = 0.8, list = FALSE)
train <- df[trainIndex, ]
test  <- df[-trainIndex, ]

train$profession <- factor(train$profession)
test$profession <- factor(test$profession)




```






#1 Random Forest
 

```{r}
library(ranger)

rf_model <- ranger(
  spendingBehaviour ~balance_eur +   working + education_level+   gender + country + profession,
  data = train,
  num.trees = 1000,
  importance = 'impurity',
  regression = TRUE
)
 
 

 
# Predict on the test set
rf_model_predictions  <- predict(rf_model, test)
 # Predict on the test set
rf_model_prob_matrix  <- predict(rf_model, test , type = 'response')
 
 
# # Confusion Matrix to get detailed evaluation metrics
conf_mat_rf_model =confusionMatrix(rf_model_predictions$predictions, test$spendingBehaviour)
conf_mat_rf_model$overall 
conf_mat_rf_model

conf_mat_rf_model$overall[1]
```
  


#2 Logistic Regression

```{r}
log_reg_model <- multinom( spendingBehaviour ~balance_eur +   working + education_level+   gender + country    , data = train)

# Predict
log_reg_model_predictions <- predict(log_reg_model, newdata = test)
log_reg_model_prob_matrix <- predict(log_reg_model, newdata = test, type = "prob")

# Evaluate
  log_reg_confusion_matrix =  confusionMatrix(log_reg_model_predictions, test$spendingBehaviour)
  log_reg_confusion_matrix$overall[1] 
```
 

#4  Decision tree

```{r}
#this took so much time so will comment

# Decision tree model
# tree_model <- rpart( spendingBehaviour ~balance_eur +   working + education_level+   gender + country + profession, data = train, method = "class")


tree_model <- rpart(
  spendingBehaviour ~ balance_eur + working + education_level + gender + country, 
  data = train, 
  method = "class",
  control = rpart.control(
    maxdepth = 4,      # Limit maximum depth of the tree
    minsplit = 20,     # Minimum number of observations to attempt a split
    minbucket = 10     # Minimum number of observations in any terminal node
  )
)


# Predict
tree_model_predictions <- predict(tree_model, newdata = test, type = "class")

tree_model_prob_matrix  <- predict(tree_model, newdata = test , type = "prob")

# Evaluate
tree_confusion_matrix= confusionMatrix(tree_model_predictions, test$spendingBehaviour)
tree_confusion_matrix$overall[1]
```

  

```{r}
 
 #caused an error so will comment

# xgb_model <- train( spendingBehaviour ~balance_eur +   working + education_level+   gender + country + profession , data = train , method = "xgbTree", 
#                     trControl = trainControl(classProbs = TRUE),
#                    tuneGrid = expand.grid(nrounds = 100, max_depth = 6, eta = 0.3, 
#                                           gamma = 0, colsample_bytree = 0.8, 
#                                           min_child_weight = 1, subsample = 0.8),
#                    verbose = TRUE) 
# 
# 
# # Predict on test set
#  
# xgb_model_prob_matrix <- predict(xgb_model, newdata = test , type = "prob")
# xgb_model_predictions <- predict(xgb_model, newdata = test , type = "raw")


```

 


Models Comparison:
To evaluate our models, we will create a df for the results
```{r}
results_df <- data.frame(
  Model = character(),
  Accuracy = numeric() 
 
)



results_df_log_reg <- data.frame(
  Model =  'Multiple Logistic Regression',
  Accuracy =  log_reg_confusion_matrix$overall[1] 
 
)

 

results_df_tree <- data.frame(
  Model =  'Decision tree',
  Accuracy = tree_confusion_matrix$overall[1]
 
)


results_df_rf_model <- data.frame(
  Model =  'Random Forest',
  Accuracy =conf_mat_rf_model$overall[1]
 
 
)

 

 


results_df <- bind_rows(results_df, results_df_rf_model , results_df_tree , results_df_log_reg)

  
 
results_df
```


We will choose the rf model
```{r}

saveRDS(rf_model , "m8.rds")

```
 

 

